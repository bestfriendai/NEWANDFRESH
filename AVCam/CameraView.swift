/*
See the LICENSE.txt file for this sampleâ€™s licensing information.

Abstract:
The main user interface for the sample app.
*/

import SwiftUI
import AVFoundation
import AVKit

@MainActor
struct CameraView<CameraModel: Camera>: PlatformView {

    @Environment(\.verticalSizeClass) var verticalSizeClass
    @Environment(\.horizontalSizeClass) var horizontalSizeClass

    @State var camera: CameraModel

    // The direction a person swipes on the camera preview or mode selector.
    @State var swipeDirection = SwipeDirection.left

    var body: some View {
        ZStack {
            // A container view that manages the placement of the preview.
            PreviewContainer(camera: camera) {
                // Conditional preview based on multi-cam mode
                if camera.isMultiCamMode {
                    // Dual camera preview with split-screen
                    DualCameraPreview(camera: camera)
                    // Handle capture events from device hardware buttons.
                    .onCameraCaptureEvent(defaultSoundDisabled: true) { event in
                        if event.phase == .ended {
                            let sound: AVCaptureEventSound
                            switch camera.captureMode {
                            case .photo:
                                sound = .cameraShutter
                                // Capture a photo when pressing a hardware button.
                                await camera.capturePhoto()
                            case .video:
                                sound = camera.captureActivity.isRecording ?
                                    .endVideoRecording : .beginVideoRecording
                                // Toggle video recording when pressing a hardware button.
                                await camera.toggleRecording()
                            }
                            // Play a sound when capturing by clicking an AirPods stem.
                            if event.shouldPlaySound {
                                event.play(sound)
                            }
                        }
                    }
                    // Focus and expose at the tapped point.
                    .onTapGesture { location in
                        Task { await camera.focusAndExpose(at: location) }
                    }
                    // Switch between capture modes by swiping left and right.
                    .simultaneousGesture(swipeGesture)
                    /// The value of `shouldFlashScreen` changes briefly to `true` when capture
                    /// starts, and then immediately changes to `false`. Use this change to
                    /// flash the screen to provide visual feedback when capturing photos.
                    .opacity(camera.shouldFlashScreen ? 0 : 1)
                } else {
                    // Single camera preview
                    CameraPreview(source: camera.previewSource)
                        // Handle capture events from device hardware buttons.
                        .onCameraCaptureEvent(defaultSoundDisabled: true) { event in
                            if event.phase == .ended {
                                let sound: AVCaptureEventSound
                                switch camera.captureMode {
                                case .photo:
                                    sound = .cameraShutter
                                    // Capture a photo when pressing a hardware button.
                                    await camera.capturePhoto()
                                case .video:
                                    sound = camera.captureActivity.isRecording ?
                                        .endVideoRecording : .beginVideoRecording
                                    // Toggle video recording when pressing a hardware button.
                                    await camera.toggleRecording()
                                }
                                // Play a sound when capturing by clicking an AirPods stem.
                                if event.shouldPlaySound {
                                    event.play(sound)
                                }
                            }
                        }
                        // Focus and expose at the tapped point.
                        .onTapGesture { location in
                            Task { await camera.focusAndExpose(at: location) }
                        }
                        // Switch between capture modes by swiping left and right.
                        .simultaneousGesture(swipeGesture)
                        /// The value of `shouldFlashScreen` changes briefly to `true` when capture
                        /// starts, and then immediately changes to `false`. Use this change to
                        /// flash the screen to provide visual feedback when capturing photos.
                        .opacity(camera.shouldFlashScreen ? 0 : 1)
                }
            }

            // Multi-cam indicator badge
            if camera.isMultiCamMode {
                VStack {
                    HStack {
                        MultiCamBadge()
                        Spacer()
                    }
                    .padding()
                    Spacer()
                }
            }

            // The main camera user interface.
            CameraUI(camera: camera, swipeDirection: $swipeDirection)
        }
    }

    var swipeGesture: some Gesture {
        DragGesture(minimumDistance: 50)
            .onEnded {
                // Capture swipe direction.
                swipeDirection = $0.translation.width < 0 ? .left : .right
            }
    }
}

#Preview {
    CameraView(camera: PreviewCameraModel())
}

enum SwipeDirection {
    case left
    case right
    case up
    case down
}
